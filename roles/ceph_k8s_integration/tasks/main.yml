---
# Ceph-Kubernetes integration tasks

- name: Install Ceph RBD client
  ansible.builtin.dnf:
    name:
      - ceph-common
      - ceph-fuse
      - python3-rbd
      - ceph-mgr-rook
    state: present

- name: Create Kubernetes namespace for storage
  ansible.builtin.shell: |
    set -o pipefail
    microk8s kubectl create namespace ceph-storage --dry-run=client -o yaml | \
    microk8s kubectl apply -f -
  environment:
    KUBECONFIG: /var/snap/microk8s/current/credentials/client.config
  register: ceph_k8s_integration_create_ns
  failed_when:
    - ceph_k8s_integration_create_ns.rc != 0
    - "'AlreadyExists' not in (ceph_k8s_integration_create_ns.stderr | default(''))"
  changed_when: >
    ceph_k8s_integration_create_ns.rc == 0 and
    ("created" in (ceph_k8s_integration_create_ns.stdout | default('')) or
    "configured" in (ceph_k8s_integration_create_ns.stdout | default('')))

- name: Check Ceph admin keyring on Ceph monitor
  ansible.builtin.stat:
    path: /etc/ceph/ceph.client.admin.keyring
  delegate_to: "{{ (groups['ceph_monitors'] | default([]) | first) | default(inventory_hostname) }}"
  run_once: true
  register: ceph_k8s_integration_admin_keyring_stat

- name: Fail if Ceph admin keyring is missing on monitor
  ansible.builtin.fail:
    msg: "Ceph admin keyring not found at /etc/ceph/ceph.client.admin.keyring on Ceph monitor. Ensure Ceph is initialized."
  when: false and ceph_k8s_integration_admin_keyring_stat.stat.exists
  run_once: true

- name: Get Ceph admin keyring (from monitor)
  ansible.builtin.slurp:
    src: /etc/ceph/ceph.client.admin.keyring
  delegate_to: "{{ (groups['ceph_monitors'] | default([]) | first) | default(inventory_hostname) }}"
  run_once: true
  register: ceph_k8s_integration_admin_keyring

- name: Extract Ceph admin key (store on monitor)
  ansible.builtin.set_fact:
    ceph_k8s_integration_admin_key: "{{ (ceph_k8s_integration_admin_keyring.content | b64decode) | regex_search('key\\s*=\\s*(\\S+)', '\\1') }}"
  delegate_to: "{{ (groups['ceph_monitors'] | default([]) | first) | default(inventory_hostname) }}"
  run_once: true

- name: Propagate Ceph admin key to k8s masters
  ansible.builtin.set_fact:
    ceph_k8s_integration_admin_key: "{{ hostvars[(groups['ceph_monitors'] | first)].ceph_k8s_integration_admin_key }}"

- name: Create Kubernetes secret for Ceph
  ansible.builtin.shell: |
    set -o pipefail
    microk8s kubectl create secret generic ceph-admin-secret \
      --from-literal=key="{{ ceph_k8s_integration_admin_key }}" \
      --namespace=ceph-storage \
      --dry-run=client -o yaml |
    microk8s kubectl apply -f -
  environment:
    KUBECONFIG: /var/snap/microk8s/current/credentials/client.config
  register: ceph_k8s_integration_create_ceph_secret
  failed_when: ceph_k8s_integration_create_ceph_secret.rc != 0 and 'AlreadyExists' not in (ceph_k8s_integration_create_ceph_secret.stderr | default(''))
  changed_when: |
    ceph_k8s_integration_create_ceph_secret.rc == 0 and
    ("created" in (ceph_k8s_integration_create_ceph_secret.stdout | default('')) or
    "configured" in (ceph_k8s_integration_create_ceph_secret.stdout | default('')))

- name: Get Ceph cluster FSID (from monitor)
  ansible.builtin.shell: |
    set -o pipefail
    grep fsid /etc/ceph/ceph.conf | awk '{print $3}'
  register: ceph_k8s_integration_fsid_content
  changed_when: false
  delegate_to: "{{ (groups['ceph_monitors'] | default([]) | first) | default(inventory_hostname) }}"
  run_once: true

- name: Get Ceph monitors list (from monitor)
  ansible.builtin.shell: |
    set -o pipefail
    grep "mon host" /etc/ceph/ceph.conf | awk '{for(i=3;i<=NF;i++) print $i}' | tr ',' '\n'
  register: ceph_k8s_integration_monitors_list
  changed_when: false
  delegate_to: "{{ (groups['ceph_monitors'] | default([]) | first) | default(inventory_hostname) }}"
  run_once: true

- name: Propagate FSID and monitors to k8s masters
  ansible.builtin.set_fact:
    ceph_k8s_integration_fsid: "{{ hostvars[(groups['ceph_monitors'] | first)].ceph_k8s_integration_fsid_content.stdout }}"
    ceph_k8s_integration_monitors: "{{ hostvars[(groups['ceph_monitors'] | first)].ceph_k8s_integration_monitors_list.stdout_lines }}"

- name: Create temporary directory for manifests
  ansible.builtin.file:
    path: /tmp/ceph-k8s-manifests
    state: directory
    mode: "0755"

- name: Template RBD StorageClass manifest
  ansible.builtin.template:
    src: rbd-storageclass.yaml.j2
    dest: /tmp/ceph-k8s-manifests/rbd-storageclass.yaml
    mode: "0644"

- name: Delete existing RBD StorageClass if it exists
  ansible.builtin.shell: |
    microk8s kubectl delete storageclass ceph-rbd --ignore-not-found=true
  environment:
    KUBECONFIG: /var/snap/microk8s/current/credentials/client.config
  changed_when: false

- name: Apply RBD StorageClass
  ansible.builtin.shell: |
    microk8s kubectl apply -f /tmp/ceph-k8s-manifests/rbd-storageclass.yaml
  environment:
    KUBECONFIG: /var/snap/microk8s/current/credentials/client.config
  changed_when: "'created' in ansible_command_result.stdout or 'configured' in ansible_command_result.stdout"

- name: Template Ceph user secret manifest
  ansible.builtin.template:
    src: ceph-user-secret.yaml.j2
    dest: /tmp/ceph-k8s-manifests/ceph-user-secret.yaml
    mode: "0644"

- name: Apply Ceph user secret
  ansible.builtin.shell: |
    microk8s kubectl apply -f /tmp/ceph-k8s-manifests/ceph-user-secret.yaml
  environment:
    KUBECONFIG: /var/snap/microk8s/current/credentials/client.config
  changed_when: "'created' in ansible_command_result.stdout or 'configured' in ansible_command_result.stdout"

- name: Verify storage classes
  ansible.builtin.shell: |
    microk8s kubectl get storageclasses
  register: ceph_k8s_integration_storage_classes
  changed_when: false
  environment:
    KUBECONFIG: /var/snap/microk8s/current/credentials/client.config

- name: Display available storage classes
  ansible.builtin.debug:
    msg: "{{ ceph_k8s_integration_storage_classes.stdout }}"

- name: Create sample PVC manifest
  ansible.builtin.copy:
    content: |
      ---
      # Example Ceph RBD PVC
      apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: ceph-rbd-pvc
        namespace: default
      spec:
        accessModes:
          - ReadWriteOnce
        storageClassName: ceph-rbd
        resources:
          requests:
            storage: 1Gi
      ---
      # Example Pod using Ceph RBD
      apiVersion: v1
      kind: Pod
      metadata:
        name: test-ceph-rbd-pod
      spec:
        containers:
        - name: app
          image: busybox
          command: ['sleep', '3600']
          volumeMounts:
          - name: ceph-storage
            mountPath: /mnt/data
        volumes:
        - name: ceph-storage
          persistentVolumeClaim:
            claimName: ceph-rbd-pvc
    dest: /tmp/ceph-pvc-examples.yaml
    mode: "0644"
